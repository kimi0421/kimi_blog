{
 "metadata": {
  "name": "",
  "signature": "sha256:5e69dcf5d1be32d15fed1889ed99f12fb34ca2520dd711e26c8370bb206bb664"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Overfitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overfitting generally occurs when a model is excessively complex, such as having too many parameters relative to the number of observations."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Regularization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Regularization is a process to introduce more information in a current model in order to avoid overfitting or ill-posed problem. It is useful for model selection reducing overfitting by adding a complexity penalty to the loss function and L1, L2 regularization are two common varaints adding to the machine learning algorithm. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take linear regression as an example, the cost function for linear regression is:\n",
      "\n",
      "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^i) - y^i)^2$$\n",
      "\n",
      "when the model is over-fitting, the cost function usually:\n",
      "\n",
      "$$ J(\\theta) \\approx 0 $$ \n",
      "\n",
      "but for the cross-validation cost function it will be huge otherwise. Regularization will avoid over-fitting, because it reduces magnitude of parameters when so many features in the model. Regularization is to penalize the cost function to make parameters smaller:\n",
      "\n",
      "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^i) - y^i)^2 + p(\\theta)$$\n",
      "\n",
      "where the penalty can be L1 or L2:\n",
      "\n",
      "$$p(\\theta) =\\frac{1}{2m} \\lambda \\sum_{i=1}^{m} \\theta_j$$ or\n",
      "\n",
      "$$p(\\theta) =\\frac{1}{2m} \\lambda \\sum_{i=1}^{m} \\theta^2_j$$\n",
      "\n",
      "One fact needs to be paid attention is not to penalize $\\theta_0$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Over"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
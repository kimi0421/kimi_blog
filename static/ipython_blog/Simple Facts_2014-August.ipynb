{
 "metadata": {
  "name": "",
  "signature": "sha256:438d37618ec4767e09e30e012a857e0e1b54c1f676a5b4ac8381c54ac09fd896"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It just help me to remember some simple facts in statistics and machine learning. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Biased and Unbiased"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Biased:\n",
      "\n",
      "$$ \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$\n",
      "\n",
      "Unbiased:\n",
      "\n",
      "$$ \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$\n",
      "\n",
      "As far as I understand, biased and unbiased are just two ways to measure variance, there are no good or bad judgment. The reason why we usually use unbiased is unbiased variance has the same expected mean value.\n",
      "\n",
      "$$\\sum_{i=1}^{n}(x_i - \\bar{x})^2 = \\sum_{i=1}^{i=n}(x_i - \\mu)^2 - n (\\bar{x} - \\mu)^2$$\n",
      "\n",
      "Thus:\n",
      "\n",
      "$$\\sum_{i=1}^{n}(x_i - \\bar{x})^2 = n\\sigma^2 - n(\\frac{\\sigma^2}{n}) = (n-1)\\sigma^2$$ "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}